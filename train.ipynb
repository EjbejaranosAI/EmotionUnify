{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "# path to the folder where you want to store data\n",
    "os.chdir('./src/datasets/CMU-MultimodalSDK')\n",
    "\n",
    "# path to the SDK folder\n",
    "SDK_PATH: Optional[str] = None\n",
    "# path to the folder where you want to store data\n",
    "DATA_PATH: Optional[str] = '.src/datasets/CMU-MultimodalSDK/data/'\n",
    "# path to a pretrained word embedding file\n",
    "WORD_EMB_PATH: Optional[str] = None\n",
    "# path to loaded word embedding matrix and corresponding word2id mapping\n",
    "CACHE_PATH: Optional[str] = '.src/datasets/CMU-MultimodalSDK/data/embedding_and_mapping.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data:  CMU_MOSI_ModifiedTimestampedWords.csd\n",
      "CMU_MOSI_OpenSmile_EB10.csd\n",
      "CMU_MOSI_openSMILE_IS09.csd\n",
      "CMU_MOSI_Opinion_Labels.csd\n",
      "CMU_MOSI_TimestampedWords.csd\n",
      "CMU_MOSI_Visual_OpenFace_2.csd\n",
      "CMU_MOSI_TimestampedWordVectors.csd\n",
      "CMU_MOSI_Visual_OpenFace_1.csd\n",
      "CMU_MOSI_Visual_Facet_41.csd\n",
      "CMU_MOSI_TimestampedPhones.csd\n",
      "CMU_MOSI_Visual_Facet_42.csd\n",
      "CMU_MOSI_COVAREP.csd\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import mmsdk\n",
    "from mmsdk import mmdatasdk as md\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "data_files = os.listdir(DATA_PATH)\n",
    "print(\"Downloaded data: \",'\\n'.join(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.831] | Success | \u001b[0mComputational sequence read from file .src/datasets/CMU-MultimodalSDK/data/CMU_MOSI_ModifiedTimestampedWords.csd ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.840] | Status  | \u001b[0mChecking the integrity of the <b'CMU_MOSI_ModifiedTimestampedWords'> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.840] | Status  | \u001b[0mChecking the format of the data in <b'CMU_MOSI_ModifiedTimestampedWords'> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.861] | Success | \u001b[0m<b'CMU_MOSI_ModifiedTimestampedWords'> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.861] | Status  | \u001b[0mChecking the format of the metadata in <b'CMU_MOSI_ModifiedTimestampedWords'> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:05.861] | Warning | \u001b[0m<b'CMU_MOSI_ModifiedTimestampedWords'> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.862] | Success | \u001b[0mComputational sequence read from file .src/datasets/CMU-MultimodalSDK/data/CMU_MOSI_Visual_Facet_41.csd ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.876] | Status  | \u001b[0mChecking the integrity of the <FACET_4.1> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.876] | Status  | \u001b[0mChecking the format of the data in <FACET_4.1> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.907] | Success | \u001b[0m<FACET_4.1> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.907] | Status  | \u001b[0mChecking the format of the metadata in <FACET_4.1> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:05.907] | Warning | \u001b[0m<FACET_4.1> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.908] | Success | \u001b[0mComputational sequence read from file .src/datasets/CMU-MultimodalSDK/data/CMU_MOSI_COVAREP.csd ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.917] | Status  | \u001b[0mChecking the integrity of the <COVAREP> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.917] | Status  | \u001b[0mChecking the format of the data in <COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.942] | Success | \u001b[0m<COVAREP> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:05.943] | Status  | \u001b[0mChecking the format of the metadata in <COVAREP> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:05.943] | Warning | \u001b[0m<COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:05.943] | Success | \u001b[0mDataset initialized successfully ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# define your different modalities - refer to the filenames of the CSD files\n",
    "visual_field = 'CMU_MOSI_Visual_Facet_41'\n",
    "acoustic_field = 'CMU_MOSI_COVAREP'\n",
    "text_field = 'CMU_MOSI_ModifiedTimestampedWords'\n",
    "\n",
    "\n",
    "features = [\n",
    "    text_field, \n",
    "    visual_field, \n",
    "    acoustic_field\n",
    "]\n",
    "\n",
    "recipe = {feat: os.path.join(DATA_PATH, feat) + '.csd' for feat in features}\n",
    "dataset = md.mmdataset(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CMU_MOSI_ModifiedTimestampedWords', 'CMU_MOSI_Visual_Facet_41', 'CMU_MOSI_COVAREP']\n",
      "================================================================================\n",
      "['03bSnISJMiM', '0h-zjBukYpk', '1DmNV9C1hbY', '1iG0909rllw', '2WGyTLYerpo', '2iD-tVS8NPw', '5W7Z1C_fDaE', '6Egk_28TtTM', '6_0THN4chvY', '73jzhE8R1TQ']\n",
      "================================================================================\n",
      "['features', 'intervals']\n",
      "================================================================================\n",
      "[5404, 2]\n",
      "================================================================================\n",
      "[5404, 47]\n",
      "[658, 1]\n",
      "[18009, 74]\n",
      "Different modalities have different number of time steps!\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset.keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field].keys())[:10])\n",
    "print(\"=\" * 80)\n",
    "\n",
    "some_id = list(dataset[visual_field].keys())[15]\n",
    "print(list(dataset[visual_field][some_id].keys()))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field][some_id]['intervals'].shape))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(list(dataset[visual_field][some_id]['features'].shape))\n",
    "print(list(dataset[text_field][some_id]['features'].shape))\n",
    "print(list(dataset[acoustic_field][some_id]['features'].shape))\n",
    "print(\"Different modalities have different number of time steps!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1m[2023-09-25 15:59:10.644] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:10.644] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:10.644] | Status  | \u001b[0mPre-alignment based on <CMU_MOSI_ModifiedTimestampedWords> computational sequence started ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:15.362] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_COVAREP> ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:16.349] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_Visual_Facet_41> ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:16.369] | Status  | \u001b[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.765] | Success | \u001b[0mAlignment to <CMU_MOSI_ModifiedTimestampedWords> complete.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.765] | Status  | \u001b[0mReplacing dataset content with aligned computational sequences\n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.782] | Success | \u001b[0mInitialized empty <CMU_MOSI_ModifiedTimestampedWords> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.782] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_ModifiedTimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.843] | Success | \u001b[0m<CMU_MOSI_ModifiedTimestampedWords> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.843] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_ModifiedTimestampedWords> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:42.843] | Warning | \u001b[0m<CMU_MOSI_ModifiedTimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.843] | Success | \u001b[0mInitialized empty <CMU_MOSI_Visual_Facet_41> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.843] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.879] | Success | \u001b[0m<CMU_MOSI_Visual_Facet_41> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.879] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:42.879] | Warning | \u001b[0m<CMU_MOSI_Visual_Facet_41> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.879] | Success | \u001b[0mInitialized empty <CMU_MOSI_COVAREP> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.879] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.911] | Success | \u001b[0m<CMU_MOSI_COVAREP> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.911] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_COVAREP> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:42.911] | Warning | \u001b[0m<CMU_MOSI_COVAREP> computational sequence does not have all the required metadata ... continuing \n"
     ]
    }
   ],
   "source": [
    "# we define a simple averaging function that does not depend on intervals\n",
    "def avg(intervals: np.array, features: np.array) -> np.array:\n",
    "    try:\n",
    "        return np.average(features, axis=0)\n",
    "    except:\n",
    "        return features\n",
    "\n",
    "# first we align to words with averaging, collapse_function receives a list of functions\n",
    "dataset.align(text_field, collapse_functions=[avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:42.988] | Success | \u001b[0mComputational sequence read from file .src/datasets/CMU-MultimodalSDK/data/CMU_MOSI_Opinion_Labels.csd ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.994] | Status  | \u001b[0mChecking the integrity of the <Opinion Segment Labels> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:42.994] | Status  | \u001b[0mChecking the format of the data in <Opinion Segment Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:43.008] | Success | \u001b[0m<Opinion Segment Labels> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.008] | Status  | \u001b[0mChecking the format of the metadata in <Opinion Segment Labels> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:43.008] | Warning | \u001b[0m<Opinion Segment Labels> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.008] | Status  | \u001b[0mUnify was called ...\n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:43.045] | Success | \u001b[0mUnify completed ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.046] | Status  | \u001b[0mPre-alignment based on <CMU_MOSI_Opinion_Labels> computational sequence started ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.116] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_COVAREP> ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.179] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_ModifiedTimestampedWords> ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.244] | Status  | \u001b[0mPre-alignment done for <CMU_MOSI_Visual_Facet_41> ...\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:43.246] | Status  | \u001b[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.407] | Success | \u001b[0mAlignment to <CMU_MOSI_Opinion_Labels> complete.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.407] | Status  | \u001b[0mReplacing dataset content with aligned computational sequences\n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.474] | Success | \u001b[0mInitialized empty <CMU_MOSI_ModifiedTimestampedWords> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.474] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_ModifiedTimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.476] | Success | \u001b[0m<CMU_MOSI_ModifiedTimestampedWords> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.476] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_ModifiedTimestampedWords> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:44.476] | Warning | \u001b[0m<CMU_MOSI_ModifiedTimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.476] | Success | \u001b[0mInitialized empty <CMU_MOSI_Visual_Facet_41> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.476] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.479] | Success | \u001b[0m<CMU_MOSI_Visual_Facet_41> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.479] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Visual_Facet_41> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:44.479] | Warning | \u001b[0m<CMU_MOSI_Visual_Facet_41> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.479] | Success | \u001b[0mInitialized empty <CMU_MOSI_COVAREP> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.479] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.481] | Success | \u001b[0m<CMU_MOSI_COVAREP> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.481] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_COVAREP> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:44.481] | Warning | \u001b[0m<CMU_MOSI_COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.481] | Success | \u001b[0mInitialized empty <CMU_MOSI_Opinion_Labels> computational sequence.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.481] | Status  | \u001b[0mChecking the format of the data in <CMU_MOSI_Opinion_Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2023-09-25 15:59:44.483] | Success | \u001b[0m<CMU_MOSI_Opinion_Labels> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2023-09-25 15:59:44.483] | Status  | \u001b[0mChecking the format of the metadata in <CMU_MOSI_Opinion_Labels> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2023-09-25 15:59:44.483] | Warning | \u001b[0m<CMU_MOSI_Opinion_Labels> computational sequence does not have all the required metadata ... continuing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "label_field = 'CMU_MOSI_Opinion_Labels'\n",
    "\n",
    "# we add and align to lables to obtain labeled segments\n",
    "# this time we don't apply collapse functions so that the temporal sequences are preserved\n",
    "label_recipe = {label_field: os.path.join(DATA_PATH, label_field + '.csd')}\n",
    "dataset.add_computational_sequences(label_recipe, destination=None)\n",
    "dataset.align(label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1iG0909rllw[3]\n"
     ]
    }
   ],
   "source": [
    "# check out what the keys look like now\n",
    "print(list(dataset[text_field].keys())[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmZoasNr4rU', 'zhpQhgha_KU', 'lXPQBPVc5Cw', 'iiK8YX8oH1E', 'tStelxIAHjw', 'nzpVDcQ0ywM', 'etzxEpPuc6I', 'cW1FSBF59ik', 'd6hH302o4v8', 'k5Y_838nuGo', 'pLTX3ipuDJI', 'jUzDDGyPkXU', 'f_pcplsH_V0', 'yvsjCA6Y5Fc', 'nbWiPyCm4g0', 'rnaNMUZpvvg', 'wMbj6ajWbic', 'cM3Yna7AavY', 'yDtzw_Y-7RU', 'vyB00TXsimI', 'dq3Nf_lMPnE', 'phBUpBr1hSo', 'd3_k5Xpfmik', 'v0zCBqDeKcE', 'tIrG4oNLFzE', 'fvVhgmXxadc', 'ob23OKe5a9Q', 'cXypl4FnoZo', 'vvZ4IcEtiZc', 'f9O3YtZ2VfI', 'c7UH_rxdZv4']\n"
     ]
    }
   ],
   "source": [
    "DATASET = md.cmu_mosi\n",
    "# obtain the train/dev/test splits - these splits are based on video IDs\n",
    "train_split = DATASET.standard_folds.standard_train_fold\n",
    "dev_split = DATASET.standard_folds.standard_valid_fold\n",
    "test_split = DATASET.standard_folds.standard_test_fold\n",
    "\n",
    "# inspect the splits: they only contain video IDs\n",
    "print(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1k/7l23nvk1643grz07p393jdv40000gn/T/ipykernel_5778/2374411930.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  acoustic = np.nan_to_num((acoustic - acoustic.mean(0, keepdims=True)) / (EPS + np.std(acoustic, axis=0, keepdims=True)))\n",
      "/var/folders/1k/7l23nvk1643grz07p393jdv40000gn/T/ipykernel_5778/2374411930.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + np.std(visual, axis=0, keepdims=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 0 datapoints have been dropped.\n"
     ]
    }
   ],
   "source": [
    "# we can see they are in the format of 'video_id[segment_no]', but the splits was specified with video_id only\n",
    "# we need to use regex or something to match the video IDs...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "\n",
    "# a sentinel epsilon for safe division, without it we will replace illegal values with a constant\n",
    "EPS = 0\n",
    "\n",
    "# construct a word2id mapping that automatically takes increment when new words are encountered\n",
    "word2id = defaultdict(lambda: len(word2id))\n",
    "UNK = word2id['<unk>']\n",
    "PAD = word2id['<pad>']\n",
    "\n",
    "# place holders for the final train/dev/test dataset\n",
    "train = []\n",
    "dev = []\n",
    "test = []\n",
    "\n",
    "# define a regular expression to extract the video ID out of the keys\n",
    "pattern = re.compile('(.*)\\[.*\\]')\n",
    "num_drop = 0 # a counter to count how many data points went into some processing issues\n",
    "\n",
    "for segment in dataset[label_field].keys():\n",
    "    \n",
    "    # get the video ID and the features out of the aligned dataset\n",
    "    vid = re.search(pattern, segment).group(1)\n",
    "    label = dataset[label_field][segment]['features']\n",
    "    _words = dataset[text_field][segment]['features']\n",
    "    _visual = dataset[visual_field][segment]['features']\n",
    "    _acoustic = dataset[acoustic_field][segment]['features']\n",
    "\n",
    "    # if the sequences are not same length after alignment, there must be some problem with some modalities\n",
    "    # we should drop it or inspect the data again\n",
    "    if not _words.shape[0] == _visual.shape[0] == _acoustic.shape[0]:\n",
    "        print(f\"Encountered datapoint {vid} with text shape {_words.shape}, visual shape {_visual.shape}, acoustic shape {_acoustic.shape}\")\n",
    "        num_drop += 1\n",
    "        continue\n",
    "\n",
    "    # remove nan values\n",
    "    label = np.nan_to_num(label)\n",
    "    _visual = np.nan_to_num(_visual)\n",
    "    _acoustic = np.nan_to_num(_acoustic)\n",
    "\n",
    "    # remove speech pause tokens - this is in general helpful\n",
    "    # we should remove speech pauses and corresponding visual/acoustic features together\n",
    "    # otherwise modalities would no longer be aligned\n",
    "    words = []\n",
    "    visual = []\n",
    "    acoustic = []\n",
    "    for i, word in enumerate(_words):\n",
    "        if word[0] != b'sp':\n",
    "            words.append(word2id[word[0].decode('utf-8')]) # SDK stores strings as bytes, decode into strings here\n",
    "            visual.append(_visual[i, :])\n",
    "            acoustic.append(_acoustic[i, :])\n",
    "\n",
    "    words = np.asarray(words)\n",
    "    visual = np.asarray(visual)\n",
    "    acoustic = np.asarray(acoustic)\n",
    "\n",
    "    # z-normalization per instance and remove nan/infs\n",
    "    visual = np.nan_to_num((visual - visual.mean(0, keepdims=True)) / (EPS + np.std(visual, axis=0, keepdims=True)))\n",
    "    acoustic = np.nan_to_num((acoustic - acoustic.mean(0, keepdims=True)) / (EPS + np.std(acoustic, axis=0, keepdims=True)))\n",
    "\n",
    "    if vid in train_split:\n",
    "        train.append(((words, visual, acoustic), label, segment))\n",
    "    elif vid in dev_split:\n",
    "        dev.append(((words, visual, acoustic), label, segment))\n",
    "    elif vid in test_split:\n",
    "        test.append(((words, visual, acoustic), label, segment))\n",
    "    else:\n",
    "        print(f\"Found video that doesn't belong to any splits: {vid}\")\n",
    "\n",
    "print(f\"Total number of {num_drop} datapoints have been dropped.\")\n",
    "\n",
    "# turn off the word2id - define a named function here to allow for pickling\n",
    "def return_unk():\n",
    "    return UNK\n",
    "word2id.default_factory = return_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1283\n",
      "229\n",
      "686\n",
      "(5, 47)\n",
      "(1, 1)\n",
      "[[2.4]]\n",
      "Total vocab size: 3143\n"
     ]
    }
   ],
   "source": [
    "# let's see the size of each set and shape of data\n",
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))\n",
    "\n",
    "print(train[0][0][1].shape)\n",
    "print(train[0][1].shape)\n",
    "print(train[0][1])\n",
    "\n",
    "print(f\"Total vocab size: {len(word2id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 8])\n",
      "torch.Size([45, 8, 47])\n",
      "torch.Size([45, 8, 74])\n",
      "tensor([[-2.4000],\n",
      "        [ 1.0000],\n",
      "        [-0.6000],\n",
      "        [-1.4000],\n",
      "        [ 0.6000],\n",
      "        [ 2.8000],\n",
      "        [-0.6000],\n",
      "        [-2.4000]])\n",
      "tensor([45, 24, 15, 15, 14, 10,  7,  5])\n"
     ]
    }
   ],
   "source": [
    "def multi_collate(batch):\n",
    "    '''\n",
    "    Collate functions assume batch = [Dataset[i] for i in index_set]\n",
    "    '''\n",
    "    # for later use we sort the batch in descending order of length\n",
    "    batch = sorted(batch, key=lambda x: x[0][0].shape[0], reverse=True)\n",
    "    \n",
    "    # get the data out of the batch - use pad sequence util functions from PyTorch to pad things\n",
    "    labels = torch.cat([torch.from_numpy(sample[1]) for sample in batch], dim=0)\n",
    "    sentences = pad_sequence([torch.LongTensor(sample[0][0]) for sample in batch], padding_value=PAD)\n",
    "    visual = pad_sequence([torch.FloatTensor(sample[0][1]) for sample in batch])\n",
    "    acoustic = pad_sequence([torch.FloatTensor(sample[0][2]) for sample in batch])\n",
    "    \n",
    "    # lengths are useful later in using RNNs\n",
    "    lengths = torch.LongTensor([sample[0][0].shape[0] for sample in batch])\n",
    "    return sentences, visual, acoustic, labels, lengths\n",
    "\n",
    "# construct dataloaders, dev and test could use around ~X3 times batch size since no_grad is used during eval\n",
    "batch_sz = 56\n",
    "train_loader = DataLoader(train, shuffle=True, batch_size=batch_sz, collate_fn=multi_collate)\n",
    "dev_loader = DataLoader(dev, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate)\n",
    "test_loader = DataLoader(test, shuffle=False, batch_size=batch_sz*3, collate_fn=multi_collate)\n",
    "\n",
    "# let's create a temporary dataloader just to see how the batch looks like\n",
    "temp_loader = iter(DataLoader(test, shuffle=True, batch_size=8, collate_fn=multi_collate))\n",
    "batch = next(temp_loader)\n",
    "\n",
    "print(batch[0].shape) # word vectors, padded to maxlen\n",
    "print(batch[1].shape) # visual features\n",
    "print(batch[2].shape) # acoustic features\n",
    "print(batch[3]) # labels\n",
    "print(batch[4]) # lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like one thing i like with the aliens is that a they are not just weak links that hide behind the\n",
      "[[1.4]]\n",
      "2WGyTLYerpo[18]\n"
     ]
    }
   ],
   "source": [
    "# Let's actually inspect the transcripts to ensure it's correct\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "examine_target = train\n",
    "idx = np.random.randint(0, len(examine_target))\n",
    "print(' '.join(list(map(lambda x: id2word[x], examine_target[idx][0][0].tolist()))))\n",
    "# print(' '.join(examine_target[idx][0]))\n",
    "print(examine_target[idx][1])\n",
    "print(examine_target[idx][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE       __init_.py    librerias.txt next_steps.md \u001b[34mwandb\u001b[m\u001b[m\n",
      "LICENSE.txt   \u001b[31mclean.sh\u001b[m\u001b[m      \u001b[34mmmsdk\u001b[m\u001b[m         optim.std\n",
      "README.md     \u001b[34mexamples\u001b[m\u001b[m      model.std     \u001b[34mrelated_repos\u001b[m\u001b[m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mls\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultimodal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marchitecture\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlate_fusion\u001b[39;00m \u001b[39mimport\u001b[39;00m LFLSTM\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "from ....src.multimodal.architecture.late_fusion import LFLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that loads data from GloVe-like embedding files\n",
    "# we will add tutorials for loading contextualized embeddings later\n",
    "# 2196017 is the vocab size of GloVe here.\n",
    "\n",
    "def load_emb(w2i, path_to_embedding, embedding_size=300, embedding_vocab=2196017, init_emb=None):\n",
    "    if init_emb is None:\n",
    "        emb_mat = np.random.randn(len(w2i), embedding_size)\n",
    "    else:\n",
    "        emb_mat = init_emb\n",
    "    f = open(path_to_embedding, 'r')\n",
    "    found = 0\n",
    "    for line in tqdm_notebook(f, total=embedding_vocab):\n",
    "        content = line.strip().split()\n",
    "        vector = np.asarray(list(map(lambda x: float(x), content[-300:])))\n",
    "        word = ' '.join(content[:-300])\n",
    "        if word in w2i:\n",
    "            idx = w2i[word]\n",
    "            emb_mat[idx, :] = vector\n",
    "            found += 1\n",
    "    print(f\"Found {found} words in the embedding file.\")\n",
    "    return torch.tensor(emb_mat).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1k/7l23nvk1643grz07p393jdv40000gn/T/ipykernel_5778/3155307217.py:51: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  train_iter = tqdm_notebook(train_loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93bfb400a1c4eb5b37d7182649977e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.306\n",
      "Validation loss: 1.3898\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bcf8867596449eaa5a85cafa926ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9546\n",
      "Validation loss: 1.3244\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7ebd1401504dcb93b351fbdfae2840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7075\n",
      "Validation loss: 1.3359\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284e4c7fee6b48f4b81624681415fa7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.558\n",
      "Validation loss: 1.3321\n",
      "Current patience: 7, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf2fe2f43be49858b87fe8bfe99ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4775\n",
      "Validation loss: 1.323\n",
      "Current patience: 6, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9983a55a1b4ceaacba741269e1f6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4025\n",
      "Validation loss: 1.3075\n",
      "Current patience: 8, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8f330f1eed4f75a525018a17b88f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3695\n",
      "Validation loss: 1.3205\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92174e1560b44598a329b7068a6dad39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3445\n",
      "Validation loss: 1.315\n",
      "Current patience: 7, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889412aeaa944b69ba47b7068091291d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3184\n",
      "Validation loss: 1.3173\n",
      "Current patience: 6, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e819423e4e4fe2912b3d63cd569b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3056\n",
      "Validation loss: 1.3121\n",
      "Current patience: 5, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1e337496ce4086b5dcaacc5158d174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3035\n",
      "Validation loss: 1.3274\n",
      "Current patience: 4, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c7aa56039c4ab0befd8f9cf09b4d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3056\n",
      "Validation loss: 1.3169\n",
      "Current patience: 3, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a006017aabcf4fa2baf597fe5ce5407b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3151\n",
      "Validation loss: 1.3042\n",
      "Current patience: 2, current trial: 3.\n",
      "Found new best model on dev set!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa32920a1254882b23c8bad8f5c6a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3015\n",
      "Validation loss: 1.3204\n",
      "Current patience: 8, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6213884ba7eb43c19f72d62fa86c0867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3106\n",
      "Validation loss: 1.3502\n",
      "Current patience: 7, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314e73eec27b4902b9e021e100b3d804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.298\n",
      "Validation loss: 1.3147\n",
      "Current patience: 6, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6f7f2cd9304e8ca7f41005c2521790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2717\n",
      "Validation loss: 1.3174\n",
      "Current patience: 5, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714a6df566204c48a620fb2dee88bdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2749\n",
      "Validation loss: 1.3216\n",
      "Current patience: 4, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ace6a5a98b4371a94e071244e102b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2783\n",
      "Validation loss: 1.3391\n",
      "Current patience: 3, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff298fe8ad9a48daa624887e759f8067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2588\n",
      "Validation loss: 1.3139\n",
      "Current patience: 2, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67293c434b8a40eb8b765fa6513c344b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.257\n",
      "Validation loss: 1.3337\n",
      "Current patience: 1, current trial: 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028378266f9c4efba79f7040c9197775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2724\n",
      "Validation loss: 1.3171\n",
      "Current patience: 0, current trial: 3.\n",
      "Running out of patience, loading previous best model.\n",
      "Current learning rate: 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35471cb2b05247c78322bc5bb4eb99e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2827\n",
      "Validation loss: 1.3091\n",
      "Current patience: 8, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859027915dbe41bb8f8ec307b50ec193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2536\n",
      "Validation loss: 1.3105\n",
      "Current patience: 7, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ae6648b7464996bd5d0b16377faa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2479\n",
      "Validation loss: 1.3137\n",
      "Current patience: 6, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e11dd70060642f9986eb74e2fdd736b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2357\n",
      "Validation loss: 1.3135\n",
      "Current patience: 5, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7422d06b93400a8a53b6d0cdffcf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.233\n",
      "Validation loss: 1.3087\n",
      "Current patience: 4, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316176b76c7e400cbaee4168755accca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2135\n",
      "Validation loss: 1.3105\n",
      "Current patience: 3, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2812a5a14c54a26a3ab4ea89d9ba79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2062\n",
      "Validation loss: 1.3092\n",
      "Current patience: 2, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fa93a578774a2b97bc32918067a1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2092\n",
      "Validation loss: 1.3157\n",
      "Current patience: 1, current trial: 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d02118603ee404d96b200ce315b625e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2005\n",
      "Validation loss: 1.3154\n",
      "Current patience: 0, current trial: 2.\n",
      "Running out of patience, loading previous best model.\n",
      "Current learning rate: 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f7c271cfac41c0a8f848d803f3c495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2858\n",
      "Validation loss: 1.3083\n",
      "Current patience: 8, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeef4dd677241febefffbfe9aa296db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2692\n",
      "Validation loss: 1.3057\n",
      "Current patience: 7, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5551293d4f54ae1b2221894b708fe3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2398\n",
      "Validation loss: 1.3087\n",
      "Current patience: 6, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57137cd46b7149abbb8f277101fa8a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2463\n",
      "Validation loss: 1.3085\n",
      "Current patience: 5, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3115c64bcbe432ebd535ef9015b53b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2198\n",
      "Validation loss: 1.3198\n",
      "Current patience: 4, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78292c5af42645c0a4bde19f65b50da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2157\n",
      "Validation loss: 1.3167\n",
      "Current patience: 3, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf75b747f3f64de6ad245966c8e96e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2058\n",
      "Validation loss: 1.315\n",
      "Current patience: 2, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d535d5199be4271b74709700004e08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2067\n",
      "Validation loss: 1.3198\n",
      "Current patience: 1, current trial: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628e80b9221a4c12ace4946f45a93e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2027\n",
      "Validation loss: 1.3108\n",
      "Current patience: 0, current trial: 1.\n",
      "Running out of patience, loading previous best model.\n",
      "Current learning rate: 1e-05\n",
      "Running out of patience, early stopping.\n",
      "Test set performance: 1.3241789945708071\n",
      "Test set accuracy is 0.5947521865889213\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "MAX_EPOCH = 1000\n",
    "\n",
    "text_size = 300\n",
    "visual_size = 47\n",
    "acoustic_size = 74\n",
    "\n",
    "# define some model settings and hyper-parameters\n",
    "input_sizes = [text_size, visual_size, acoustic_size]\n",
    "hidden_sizes = [int(text_size * 1.5), int(visual_size * 1.5), int(acoustic_size * 1.5)]\n",
    "fc1_size = sum(hidden_sizes) // 2\n",
    "dropout = 0.25\n",
    "output_size = 1\n",
    "curr_patience = patience = 8\n",
    "num_trials = 3\n",
    "grad_clip_value = 1.0\n",
    "weight_decay = 0.1\n",
    "\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    pretrained_emb, word2id = torch.load(CACHE_PATH)\n",
    "elif WORD_EMB_PATH is not None:\n",
    "    pretrained_emb = load_emb(word2id, WORD_EMB_PATH)\n",
    "    torch.save((pretrained_emb, word2id), CACHE_PATH)\n",
    "else:\n",
    "    pretrained_emb = None\n",
    "\n",
    "model = LFLSTM(input_sizes, hidden_sizes, fc1_size, output_size, dropout)\n",
    "if pretrained_emb is not None:\n",
    "    model.embed.weight.data = pretrained_emb\n",
    "model.embed.requires_grad = False\n",
    "optimizer = Adam([param for param in model.parameters() if param.requires_grad], weight_decay=weight_decay)\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.L1Loss(reduction='sum')\n",
    "criterion_test = nn.L1Loss(reduction='sum')\n",
    "best_valid_loss = float('inf')\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "lr_scheduler.step() # for some reason it seems the StepLR needs to be stepped once first\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    model.train()\n",
    "    train_iter = tqdm(train_loader)\n",
    "    train_loss = 0.0\n",
    "    for batch in train_iter:\n",
    "        model.zero_grad()\n",
    "        t, v, a, y, l = batch\n",
    "        batch_size = t.size(0)\n",
    "        if CUDA:\n",
    "            t = t.cuda()\n",
    "            v = v.cuda()\n",
    "            a = a.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        y_tilde = model(t, v, a, l)\n",
    "        loss = criterion(y_tilde, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_([param for param in model.parameters() if param.requires_grad], grad_clip_value)\n",
    "        optimizer.step()\n",
    "        train_iter.set_description(f\"Epoch {e}/{MAX_EPOCH}, current batch loss: {round(loss.item()/batch_size, 4)}\")\n",
    "        train_loss += loss.item()\n",
    "    train_loss = train_loss / len(train)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Training loss: {round(train_loss, 4)}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for batch in dev_loader:\n",
    "            model.zero_grad()\n",
    "            t, v, a, y, l = batch\n",
    "            if CUDA:\n",
    "                t = t.cuda()\n",
    "                v = v.cuda()\n",
    "                a = a.cuda()\n",
    "                y = y.cuda()\n",
    "                l = l.cuda()\n",
    "            y_tilde = model(t, v, a, l)\n",
    "            loss = criterion(y_tilde, y)\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    valid_loss = valid_loss/len(dev)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f\"Validation loss: {round(valid_loss, 4)}\")\n",
    "    print(f\"Current patience: {curr_patience}, current trial: {num_trials}.\")\n",
    "    if valid_loss <= best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print(\"Found new best model on dev set!\")\n",
    "        torch.save(model.state_dict(), 'model.std')\n",
    "        torch.save(optimizer.state_dict(), 'optim.std')\n",
    "        curr_patience = patience\n",
    "    else:\n",
    "        curr_patience -= 1\n",
    "        if curr_patience <= -1:\n",
    "            print(\"Running out of patience, loading previous best model.\")\n",
    "            num_trials -= 1\n",
    "            curr_patience = patience\n",
    "            model.load_state_dict(torch.load('model.std'))\n",
    "            optimizer.load_state_dict(torch.load('optim.std'))\n",
    "            lr_scheduler.step()\n",
    "            print(f\"Current learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "    \n",
    "    if num_trials <= 0:\n",
    "        print(\"Running out of patience, early stopping.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('model.std'))\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        model.zero_grad()\n",
    "        t, v, a, y, l = batch\n",
    "        if CUDA:\n",
    "            t = t.cuda()\n",
    "            v = v.cuda()\n",
    "            a = a.cuda()\n",
    "            y = y.cuda()\n",
    "            l = l.cuda()\n",
    "        y_tilde = model(t, v, a, l)\n",
    "        loss = criterion_test(y_tilde, y)\n",
    "        y_true.append(y_tilde.detach().cpu().numpy())\n",
    "        y_pred.append(y.detach().cpu().numpy())\n",
    "        test_loss += loss.item()\n",
    "print(f\"Test set performance: {test_loss/len(test)}\")\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "                  \n",
    "y_true_bin = y_true >= 0\n",
    "y_pred_bin = y_pred >= 0\n",
    "bin_acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "print(f\"Test set accuracy is {bin_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotionunify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
