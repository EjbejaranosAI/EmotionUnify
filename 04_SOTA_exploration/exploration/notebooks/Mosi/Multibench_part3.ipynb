{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqi5M8q2RJ9gqDaXdfL/Tc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EjbejaranosAI/EmotionUnify/blob/main/Multibench_part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mosi dataset with head classifier"
      ],
      "metadata": {
        "id": "EaKS6dMCGFTt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MmmWiP9FZ73",
        "outputId": "82eb3e28-7f1a-462f-b094-72b78dc88c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiBench'...\n",
            "remote: Enumerating objects: 6931, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 6931 (delta 65), reused 121 (delta 60), pack-reused 6789\u001b[K\n",
            "Receiving objects: 100% (6931/6931), 51.06 MiB | 11.15 MiB/s, done.\n",
            "Resolving deltas: 100% (4251/4251), done.\n",
            "/content/MultiBench\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench\n",
        "!pip install -q memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import sys\n",
        "import gdown\n",
        "from torch import nn\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Download the file to the directory\n",
        "url = 'https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU'\n",
        "output = 'data/mosi_raw.pkl'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "tRNVyMS2FjcP",
        "outputId": "ae01f61f-2ef4-43c4-c438-08f1b5d97de5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU\n",
            "To: /content/MultiBench/data/mosi_raw.pkl\n",
            "100%|██████████| 357M/357M [00:04<00:00, 78.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/mosi_raw.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataloaders for MOSI, and import that data using the path we stored the MOSI_RAW.pkl file to."
      ],
      "metadata": {
        "id": "9e6ZmhX-Gzo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.affect.get_data import get_dataloader # noqa\n",
        "traindata, validdata, testdata = \\\n",
        "    get_dataloader('/content/MultiBench/data/mosi_raw.pkl', robust_test=False)"
      ],
      "metadata": {
        "id": "LXAeWF8zFkGF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definning the encoder and decoder modules for each modality, taken from the associated section of MultiBench."
      ],
      "metadata": {
        "id": "pHusYzj9GtVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unimodals.common_models import GRU, MLP # noqa\n",
        "from fusions.MCTN import Encoder, Decoder # noqa\n",
        "\n",
        "\n",
        "max_seq = 20\n",
        "feature_dim = 300\n",
        "hidden_dim = 32\n",
        "\n",
        "encoder0 = Encoder(feature_dim, hidden_dim, n_layers=1, dropout=0.0).cuda()\n",
        "decoder0 = Decoder(hidden_dim, feature_dim, n_layers=1, dropout=0.0).cuda()\n",
        "encoder1 = Encoder(hidden_dim, hidden_dim, n_layers=1, dropout=0.0).cuda()\n",
        "decoder1 = Decoder(hidden_dim, feature_dim, n_layers=1, dropout=0.0).cuda()\n",
        "\n",
        "reg_encoder = nn.GRU(hidden_dim, 32).cuda()"
      ],
      "metadata": {
        "id": "7NnZDm3QFnQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the classification head for our model:"
      ],
      "metadata": {
        "id": "pxrOYDdwGg9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unimodals.common_models import MLP # noqa\n",
        "head = MLP(32, 64, 1).cuda()"
      ],
      "metadata": {
        "id": "lKi7thPjF1Te"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from private_test_scripts.all_in_one import all_in_one_train # noqa\n",
        "from training_structures.MCTN_Level2 import train, test # noqa\n",
        "\n",
        "allmodules = [encoder0, decoder0, encoder1, decoder1, reg_encoder, head]\n",
        "\n",
        "\n",
        "def trainprocess():\n",
        "    train(\n",
        "        traindata, validdata,\n",
        "        encoder0, decoder0, encoder1, decoder1,\n",
        "        reg_encoder, head,\n",
        "        criterion_t0=nn.MSELoss(), criterion_c=nn.MSELoss(),\n",
        "        criterion_t1=nn.MSELoss(), criterion_r=nn.L1Loss(),\n",
        "        max_seq_len=20,\n",
        "        mu_t0=0.01, mu_c=0.01, mu_t1=0.01,\n",
        "        dropout_p=0.15, early_stop=False, patience_num=15,\n",
        "        lr=1e-4, weight_decay=0.01, op_type=torch.optim.AdamW,\n",
        "        epoch=200, model_save='best_mctn.pt')\n",
        "\n",
        "\n",
        "all_in_one_train(trainprocess, allmodules)\n",
        "\n",
        "model = torch.load('best_mctn.pt').cuda()\n",
        "\n",
        "test(model, testdata, 'mosi', no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rOODY1UF4Kv",
        "outputId": "6d3b9a51-a3d3-43db-906d-ba4be1b09f6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start training ---------->>\n",
            "Train Epoch 0, total loss: 3.07175874710083, regression loss: 1.3455722332000732, embedding loss: 1.7261865139007568\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 0, MAE: 1.416121482849121, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 1, total loss: 3.0539612770080566, regression loss: 1.335289716720581, embedding loss: 1.7186715602874756\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 1, MAE: 1.414206624031067, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 2, total loss: 3.014385461807251, regression loss: 1.2960611581802368, embedding loss: 1.7183243036270142\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 2, MAE: 1.412585735321045, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 3, total loss: 3.0526857376098633, regression loss: 1.3309831619262695, embedding loss: 1.7217025756835938\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 3, MAE: 1.412475347518921, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 4, total loss: 3.0324857234954834, regression loss: 1.3196847438812256, embedding loss: 1.7128009796142578\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 4, MAE: 1.411444067955017, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 5, total loss: 3.0315749645233154, regression loss: 1.323570966720581, embedding loss: 1.7080039978027344\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 5, MAE: 1.4102541208267212, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 6, total loss: 3.0262060165405273, regression loss: 1.3152618408203125, embedding loss: 1.7109441757202148\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 6, MAE: 1.4100233316421509, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 7, total loss: 3.0195682048797607, regression loss: 1.3133002519607544, embedding loss: 1.7062679529190063\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 7, MAE: 1.4116358757019043, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "start training ---------->>\n",
            "Train Epoch 8, total loss: 3.0168166160583496, regression loss: 1.3092715740203857, embedding loss: 1.7075450420379639\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 8, MAE: 1.4096615314483643, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 9, total loss: 3.0173871517181396, regression loss: 1.30411958694458, embedding loss: 1.7132675647735596\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 9, MAE: 1.4081833362579346, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 10, total loss: 2.9636969566345215, regression loss: 1.25191330909729, embedding loss: 1.7117836475372314\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 10, MAE: 1.4025825262069702, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 11, total loss: 2.9377119541168213, regression loss: 1.2288461923599243, embedding loss: 1.708865761756897\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 11, MAE: 1.3954397439956665, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 12, total loss: 2.8955483436584473, regression loss: 1.1732804775238037, embedding loss: 1.7222678661346436\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 12, MAE: 1.3861700296401978, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 13, total loss: 2.8130412101745605, regression loss: 1.1144490242004395, embedding loss: 1.698592185974121\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 13, MAE: 1.375560998916626, Acc1: 0.5841121495327103, Acc2: 0.6169154228855721\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 14, total loss: 2.8317370414733887, regression loss: 1.0923904180526733, embedding loss: 1.7393466234207153\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 14, MAE: 1.3757922649383545, Acc1: 0.6682242990654206, Acc2: 0.681592039800995\n",
            "start training ---------->>\n",
            "Train Epoch 15, total loss: 2.7856740951538086, regression loss: 1.076786994934082, embedding loss: 1.7088871002197266\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 15, MAE: 1.3623478412628174, Acc1: 0.5934579439252337, Acc2: 0.6268656716417911\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 16, total loss: 2.724135398864746, regression loss: 1.0154087543487549, embedding loss: 1.7087266445159912\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 16, MAE: 1.3561723232269287, Acc1: 0.5934579439252337, Acc2: 0.6268656716417911\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 17, total loss: 2.7508044242858887, regression loss: 1.0428649187088013, embedding loss: 1.7079395055770874\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 17, MAE: 1.3567191362380981, Acc1: 0.5700934579439252, Acc2: 0.6069651741293532\n",
            "start training ---------->>\n",
            "Train Epoch 18, total loss: 2.7013680934906006, regression loss: 0.9956395030021667, embedding loss: 1.705728530883789\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 18, MAE: 1.3579380512237549, Acc1: 0.5841121495327103, Acc2: 0.6169154228855721\n",
            "start training ---------->>\n",
            "Train Epoch 19, total loss: 2.7019519805908203, regression loss: 0.9964935779571533, embedding loss: 1.705458402633667\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 19, MAE: 1.3657958507537842, Acc1: 0.602803738317757, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 20, total loss: 2.6852264404296875, regression loss: 0.9714857339859009, embedding loss: 1.7137407064437866\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 20, MAE: 1.355735421180725, Acc1: 0.6214953271028038, Acc2: 0.6517412935323383\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 21, total loss: 2.68825101852417, regression loss: 0.9692363142967224, embedding loss: 1.7190146446228027\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 21, MAE: 1.3587632179260254, Acc1: 0.5934579439252337, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 22, total loss: 2.6953694820404053, regression loss: 0.9497951865196228, embedding loss: 1.7455742359161377\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 22, MAE: 1.363162875175476, Acc1: 0.6682242990654206, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 23, total loss: 2.641582727432251, regression loss: 0.9426064491271973, embedding loss: 1.6989762783050537\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 23, MAE: 1.3492950201034546, Acc1: 0.616822429906542, Acc2: 0.6467661691542289\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 24, total loss: 2.6699159145355225, regression loss: 0.9589889049530029, embedding loss: 1.7109270095825195\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 24, MAE: 1.3587684631347656, Acc1: 0.5747663551401869, Acc2: 0.6119402985074627\n",
            "start training ---------->>\n",
            "Train Epoch 25, total loss: 2.683563709259033, regression loss: 0.982331395149231, embedding loss: 1.7012323141098022\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 25, MAE: 1.3517392873764038, Acc1: 0.6635514018691588, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 26, total loss: 2.64772629737854, regression loss: 0.9213194251060486, embedding loss: 1.7264068126678467\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 26, MAE: 1.3525199890136719, Acc1: 0.7149532710280374, Acc2: 0.736318407960199\n",
            "start training ---------->>\n",
            "Train Epoch 27, total loss: 2.661062002182007, regression loss: 0.9465689063072205, embedding loss: 1.7144930362701416\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 27, MAE: 1.3721849918365479, Acc1: 0.6542056074766355, Acc2: 0.681592039800995\n",
            "start training ---------->>\n",
            "Train Epoch 28, total loss: 2.6440117359161377, regression loss: 0.9320523142814636, embedding loss: 1.7119593620300293\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 28, MAE: 1.3510844707489014, Acc1: 0.6588785046728972, Acc2: 0.6865671641791045\n",
            "start training ---------->>\n",
            "Train Epoch 29, total loss: 2.5913076400756836, regression loss: 0.8851255774497986, embedding loss: 1.7061820030212402\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 29, MAE: 1.3553105592727661, Acc1: 0.6588785046728972, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 30, total loss: 2.606316566467285, regression loss: 0.8949514031410217, embedding loss: 1.7113652229309082\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 30, MAE: 1.352169156074524, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 31, total loss: 2.6097824573516846, regression loss: 0.907625675201416, embedding loss: 1.7021567821502686\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 31, MAE: 1.3502693176269531, Acc1: 0.6635514018691588, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 32, total loss: 2.585062265396118, regression loss: 0.8803951740264893, embedding loss: 1.704667091369629\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 32, MAE: 1.3551750183105469, Acc1: 0.6728971962616822, Acc2: 0.7014925373134329\n",
            "start training ---------->>\n",
            "Train Epoch 33, total loss: 2.603553056716919, regression loss: 0.8960067629814148, embedding loss: 1.7075462341308594\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 33, MAE: 1.3511565923690796, Acc1: 0.6635514018691588, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 34, total loss: 2.588178873062134, regression loss: 0.8801643252372742, embedding loss: 1.7080144882202148\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 34, MAE: 1.3394107818603516, Acc1: 0.6682242990654206, Acc2: 0.6965174129353234\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 35, total loss: 2.57145094871521, regression loss: 0.8624858856201172, embedding loss: 1.7089650630950928\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 35, MAE: 1.3666430711746216, Acc1: 0.705607476635514, Acc2: 0.7313432835820896\n",
            "start training ---------->>\n",
            "Train Epoch 36, total loss: 2.5853872299194336, regression loss: 0.8685057759284973, embedding loss: 1.716881513595581\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 36, MAE: 1.3532741069793701, Acc1: 0.6822429906542056, Acc2: 0.7114427860696517\n",
            "start training ---------->>\n",
            "Train Epoch 37, total loss: 2.5830416679382324, regression loss: 0.870922327041626, embedding loss: 1.7121193408966064\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 37, MAE: 1.3455396890640259, Acc1: 0.6588785046728972, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 38, total loss: 2.5813562870025635, regression loss: 0.8733234405517578, embedding loss: 1.7080328464508057\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 38, MAE: 1.3565523624420166, Acc1: 0.6822429906542056, Acc2: 0.7114427860696517\n",
            "start training ---------->>\n",
            "Train Epoch 39, total loss: 2.6116104125976562, regression loss: 0.8857529759407043, embedding loss: 1.7258574962615967\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 39, MAE: 1.3509330749511719, Acc1: 0.6635514018691588, Acc2: 0.6915422885572139\n",
            "start training ---------->>\n",
            "Train Epoch 40, total loss: 2.555304527282715, regression loss: 0.8490697145462036, embedding loss: 1.7062348127365112\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 40, MAE: 1.3592973947525024, Acc1: 0.6495327102803738, Acc2: 0.681592039800995\n",
            "start training ---------->>\n",
            "Train Epoch 41, total loss: 2.547760009765625, regression loss: 0.8462191224098206, embedding loss: 1.7015409469604492\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 41, MAE: 1.3689006567001343, Acc1: 0.6635514018691588, Acc2: 0.6965174129353234\n",
            "start training ---------->>\n",
            "Train Epoch 42, total loss: 2.5717997550964355, regression loss: 0.8539756536483765, embedding loss: 1.717824101448059\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 42, MAE: 1.3478738069534302, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 43, total loss: 2.5299131870269775, regression loss: 0.8293104767799377, embedding loss: 1.7006027698516846\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 43, MAE: 1.349361777305603, Acc1: 0.6121495327102804, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 44, total loss: 2.5214900970458984, regression loss: 0.8195441365242004, embedding loss: 1.7019460201263428\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 44, MAE: 1.348380446434021, Acc1: 0.6214953271028038, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 45, total loss: 2.5476362705230713, regression loss: 0.850821316242218, embedding loss: 1.696815013885498\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 45, MAE: 1.3372764587402344, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 46, total loss: 2.4902257919311523, regression loss: 0.786730945110321, embedding loss: 1.7034947872161865\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 46, MAE: 1.34983491897583, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 47, total loss: 2.495380401611328, regression loss: 0.7903164625167847, embedding loss: 1.7050639390945435\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 47, MAE: 1.3307521343231201, Acc1: 0.6214953271028038, Acc2: 0.6567164179104478\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 48, total loss: 2.496927499771118, regression loss: 0.7906895875930786, embedding loss: 1.7062379121780396\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 48, MAE: 1.3523108959197998, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 49, total loss: 2.5032405853271484, regression loss: 0.7914782762527466, embedding loss: 1.7117623090744019\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 49, MAE: 1.3478410243988037, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 50, total loss: 2.55778169631958, regression loss: 0.8339955806732178, embedding loss: 1.7237861156463623\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 50, MAE: 1.3394731283187866, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 51, total loss: 2.5076169967651367, regression loss: 0.8122222423553467, embedding loss: 1.69539475440979\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 51, MAE: 1.3297641277313232, Acc1: 0.6308411214953271, Acc2: 0.6616915422885572\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 52, total loss: 2.528588056564331, regression loss: 0.8196592926979065, embedding loss: 1.7089288234710693\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 52, MAE: 1.3377431631088257, Acc1: 0.6121495327102804, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 53, total loss: 2.5172500610351562, regression loss: 0.8233117461204529, embedding loss: 1.6939382553100586\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 53, MAE: 1.3350353240966797, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 54, total loss: 2.5070831775665283, regression loss: 0.8031966686248779, embedding loss: 1.7038865089416504\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 54, MAE: 1.3379262685775757, Acc1: 0.6542056074766355, Acc2: 0.6865671641791045\n",
            "start training ---------->>\n",
            "Train Epoch 55, total loss: 2.515062093734741, regression loss: 0.8173677921295166, embedding loss: 1.6976943016052246\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 55, MAE: 1.3420038223266602, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 56, total loss: 2.4938526153564453, regression loss: 0.773795485496521, embedding loss: 1.7200571298599243\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 56, MAE: 1.3479976654052734, Acc1: 0.6214953271028038, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 57, total loss: 2.468822717666626, regression loss: 0.7679922580718994, embedding loss: 1.7008304595947266\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 57, MAE: 1.3440742492675781, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 58, total loss: 2.528165340423584, regression loss: 0.802760660648346, embedding loss: 1.7254047393798828\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 58, MAE: 1.337509274482727, Acc1: 0.6401869158878505, Acc2: 0.6716417910447762\n",
            "start training ---------->>\n",
            "Train Epoch 59, total loss: 2.5099937915802, regression loss: 0.8069233298301697, embedding loss: 1.7030704021453857\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 59, MAE: 1.3400346040725708, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 60, total loss: 2.4855997562408447, regression loss: 0.771356999874115, embedding loss: 1.714242696762085\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 60, MAE: 1.3296177387237549, Acc1: 0.6495327102803738, Acc2: 0.681592039800995\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 61, total loss: 2.4756267070770264, regression loss: 0.7610144019126892, embedding loss: 1.7146122455596924\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 61, MAE: 1.3347034454345703, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 62, total loss: 2.4916951656341553, regression loss: 0.7929403185844421, embedding loss: 1.6987547874450684\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 62, MAE: 1.3461360931396484, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 63, total loss: 2.474606513977051, regression loss: 0.76959627866745, embedding loss: 1.705010175704956\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 63, MAE: 1.3351420164108276, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 64, total loss: 2.454730987548828, regression loss: 0.7480741739273071, embedding loss: 1.706656813621521\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 64, MAE: 1.3266397714614868, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 65, total loss: 2.5071163177490234, regression loss: 0.8105132579803467, embedding loss: 1.6966030597686768\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 65, MAE: 1.3286722898483276, Acc1: 0.5794392523364486, Acc2: 0.6169154228855721\n",
            "start training ---------->>\n",
            "Train Epoch 66, total loss: 2.516315460205078, regression loss: 0.8007106781005859, embedding loss: 1.7156047821044922\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 66, MAE: 1.335050344467163, Acc1: 0.5794392523364486, Acc2: 0.6169154228855721\n",
            "start training ---------->>\n",
            "Train Epoch 67, total loss: 2.477001905441284, regression loss: 0.7589743733406067, embedding loss: 1.7180275917053223\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 67, MAE: 1.3333449363708496, Acc1: 0.616822429906542, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 68, total loss: 2.431736707687378, regression loss: 0.7325950264930725, embedding loss: 1.6991417407989502\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 68, MAE: 1.336916208267212, Acc1: 0.616822429906542, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 69, total loss: 2.450030565261841, regression loss: 0.7488042712211609, embedding loss: 1.7012262344360352\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 69, MAE: 1.3225117921829224, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 70, total loss: 2.468738555908203, regression loss: 0.765470027923584, embedding loss: 1.7032685279846191\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 70, MAE: 1.3211896419525146, Acc1: 0.6121495327102804, Acc2: 0.6467661691542289\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 71, total loss: 2.4424211978912354, regression loss: 0.7471737265586853, embedding loss: 1.6952474117279053\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 71, MAE: 1.3423165082931519, Acc1: 0.602803738317757, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 72, total loss: 2.4150290489196777, regression loss: 0.7166427969932556, embedding loss: 1.6983861923217773\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 72, MAE: 1.3361964225769043, Acc1: 0.6074766355140186, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 73, total loss: 2.406407594680786, regression loss: 0.7084481716156006, embedding loss: 1.6979594230651855\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 73, MAE: 1.3386304378509521, Acc1: 0.6074766355140186, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 74, total loss: 2.4289698600769043, regression loss: 0.7276175618171692, embedding loss: 1.7013523578643799\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 74, MAE: 1.3303325176239014, Acc1: 0.6074766355140186, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 75, total loss: 2.4708845615386963, regression loss: 0.7746321558952332, embedding loss: 1.6962523460388184\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 75, MAE: 1.335155725479126, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 76, total loss: 2.4358720779418945, regression loss: 0.7269651889801025, embedding loss: 1.708906888961792\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 76, MAE: 1.3301340341567993, Acc1: 0.616822429906542, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 77, total loss: 2.4012348651885986, regression loss: 0.7064522504806519, embedding loss: 1.6947826147079468\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 77, MAE: 1.3319391012191772, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 78, total loss: 2.439507007598877, regression loss: 0.7257092595100403, embedding loss: 1.7137978076934814\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 78, MAE: 1.335483431816101, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 79, total loss: 2.440974235534668, regression loss: 0.7355085015296936, embedding loss: 1.7054657936096191\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 79, MAE: 1.337028980255127, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 80, total loss: 2.4194729328155518, regression loss: 0.7052235007286072, embedding loss: 1.7142493724822998\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 80, MAE: 1.3399304151535034, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 81, total loss: 2.4411792755126953, regression loss: 0.7349141836166382, embedding loss: 1.7062650918960571\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 81, MAE: 1.3350756168365479, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 82, total loss: 2.4280385971069336, regression loss: 0.7162201404571533, embedding loss: 1.7118184566497803\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 82, MAE: 1.3357264995574951, Acc1: 0.6121495327102804, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 83, total loss: 2.422642230987549, regression loss: 0.7027914524078369, embedding loss: 1.719850778579712\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 83, MAE: 1.3483986854553223, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 84, total loss: 2.4035067558288574, regression loss: 0.704720139503479, embedding loss: 1.6987866163253784\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 84, MAE: 1.3232898712158203, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 85, total loss: 2.418020248413086, regression loss: 0.714888870716095, embedding loss: 1.7031314373016357\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 85, MAE: 1.3322596549987793, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 86, total loss: 2.425347328186035, regression loss: 0.7197314500808716, embedding loss: 1.7056158781051636\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 86, MAE: 1.3356229066848755, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 87, total loss: 2.4075233936309814, regression loss: 0.7053918838500977, embedding loss: 1.7021315097808838\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 87, MAE: 1.3273651599884033, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 88, total loss: 2.405283212661743, regression loss: 0.6814286112785339, embedding loss: 1.7238545417785645\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 88, MAE: 1.3336139917373657, Acc1: 0.616822429906542, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 89, total loss: 2.388272762298584, regression loss: 0.6716750860214233, embedding loss: 1.7165976762771606\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 89, MAE: 1.3279914855957031, Acc1: 0.6121495327102804, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 90, total loss: 2.368983507156372, regression loss: 0.6720445156097412, embedding loss: 1.6969389915466309\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 90, MAE: 1.3436570167541504, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 91, total loss: 2.3692634105682373, regression loss: 0.6632799506187439, embedding loss: 1.7059834003448486\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 91, MAE: 1.3234738111495972, Acc1: 0.6121495327102804, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 92, total loss: 2.3821375370025635, regression loss: 0.675487756729126, embedding loss: 1.7066497802734375\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 92, MAE: 1.3366293907165527, Acc1: 0.5794392523364486, Acc2: 0.6169154228855721\n",
            "start training ---------->>\n",
            "Train Epoch 93, total loss: 2.4147117137908936, regression loss: 0.7029123306274414, embedding loss: 1.7117993831634521\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 93, MAE: 1.3329182863235474, Acc1: 0.5794392523364486, Acc2: 0.6169154228855721\n",
            "start training ---------->>\n",
            "Train Epoch 94, total loss: 2.3877949714660645, regression loss: 0.692716121673584, embedding loss: 1.6950788497924805\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 94, MAE: 1.328670859336853, Acc1: 0.616822429906542, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 95, total loss: 2.40317964553833, regression loss: 0.6970125436782837, embedding loss: 1.7061671018600464\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 95, MAE: 1.3370335102081299, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 96, total loss: 2.3746931552886963, regression loss: 0.670225977897644, embedding loss: 1.7044671773910522\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 96, MAE: 1.3332651853561401, Acc1: 0.616822429906542, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 97, total loss: 2.359928607940674, regression loss: 0.6658123135566711, embedding loss: 1.6941163539886475\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 97, MAE: 1.332275390625, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 98, total loss: 2.376760721206665, regression loss: 0.677699863910675, embedding loss: 1.6990609169006348\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 98, MAE: 1.3315231800079346, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 99, total loss: 2.379098653793335, regression loss: 0.6759659051895142, embedding loss: 1.7031327486038208\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 99, MAE: 1.3282421827316284, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 100, total loss: 2.3626952171325684, regression loss: 0.6543735265731812, embedding loss: 1.7083216905593872\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 100, MAE: 1.326450228691101, Acc1: 0.6121495327102804, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 101, total loss: 2.375957489013672, regression loss: 0.6729772090911865, embedding loss: 1.7029802799224854\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 101, MAE: 1.321200966835022, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 102, total loss: 2.4453437328338623, regression loss: 0.7409645915031433, embedding loss: 1.7043790817260742\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 102, MAE: 1.3334110975265503, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 103, total loss: 2.3769235610961914, regression loss: 0.6768091320991516, embedding loss: 1.7001144886016846\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 103, MAE: 1.322528600692749, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 104, total loss: 2.3344337940216064, regression loss: 0.62354576587677, embedding loss: 1.7108880281448364\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 104, MAE: 1.3347042798995972, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 105, total loss: 2.331986427307129, regression loss: 0.6323912739753723, embedding loss: 1.6995952129364014\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 105, MAE: 1.3311944007873535, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 106, total loss: 2.3363659381866455, regression loss: 0.630547821521759, embedding loss: 1.7058181762695312\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 106, MAE: 1.3247239589691162, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 107, total loss: 2.366126775741577, regression loss: 0.6485047340393066, embedding loss: 1.7176220417022705\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 107, MAE: 1.3308093547821045, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 108, total loss: 2.365159749984741, regression loss: 0.6514368653297424, embedding loss: 1.7137229442596436\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 108, MAE: 1.3413984775543213, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 109, total loss: 2.363171339035034, regression loss: 0.661250650882721, embedding loss: 1.701920747756958\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 109, MAE: 1.34062659740448, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 110, total loss: 2.381699800491333, regression loss: 0.660262942314148, embedding loss: 1.721436858177185\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 110, MAE: 1.3350226879119873, Acc1: 0.6121495327102804, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 111, total loss: 2.3226563930511475, regression loss: 0.6155654191970825, embedding loss: 1.707090973854065\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 111, MAE: 1.3256841897964478, Acc1: 0.616822429906542, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 112, total loss: 2.346463441848755, regression loss: 0.6430695652961731, embedding loss: 1.7033939361572266\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 112, MAE: 1.3262708187103271, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 113, total loss: 2.339405059814453, regression loss: 0.6385565400123596, embedding loss: 1.7008485794067383\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 113, MAE: 1.3332619667053223, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 114, total loss: 2.3428547382354736, regression loss: 0.6356170773506165, embedding loss: 1.707237720489502\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 114, MAE: 1.3301260471343994, Acc1: 0.6261682242990654, Acc2: 0.6666666666666666\n",
            "start training ---------->>\n",
            "Train Epoch 115, total loss: 2.3201677799224854, regression loss: 0.6184921264648438, embedding loss: 1.7016756534576416\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 115, MAE: 1.3359280824661255, Acc1: 0.616822429906542, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 116, total loss: 2.377701759338379, regression loss: 0.6820904612541199, embedding loss: 1.6956112384796143\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 116, MAE: 1.3370729684829712, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 117, total loss: 2.3249545097351074, regression loss: 0.6147292852401733, embedding loss: 1.710225224494934\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 117, MAE: 1.3265674114227295, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 118, total loss: 2.34063458442688, regression loss: 0.6307434439659119, embedding loss: 1.7098910808563232\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 118, MAE: 1.341613531112671, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 119, total loss: 2.3431413173675537, regression loss: 0.6367357969284058, embedding loss: 1.706405520439148\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 119, MAE: 1.3234797716140747, Acc1: 0.6121495327102804, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 120, total loss: 2.361022710800171, regression loss: 0.6537535786628723, embedding loss: 1.7072691917419434\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 120, MAE: 1.3304457664489746, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 121, total loss: 2.336491584777832, regression loss: 0.6116478443145752, embedding loss: 1.7248437404632568\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 121, MAE: 1.3307756185531616, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 122, total loss: 2.2977888584136963, regression loss: 0.5982464551925659, embedding loss: 1.6995424032211304\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 122, MAE: 1.3234864473342896, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 123, total loss: 2.3349106311798096, regression loss: 0.6294851303100586, embedding loss: 1.705425500869751\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 123, MAE: 1.327897310256958, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 124, total loss: 2.3403396606445312, regression loss: 0.6305618286132812, embedding loss: 1.70977783203125\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 124, MAE: 1.3205723762512207, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 125, total loss: 2.3224048614501953, regression loss: 0.6222682595252991, embedding loss: 1.700136661529541\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 125, MAE: 1.32377290725708, Acc1: 0.616822429906542, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 126, total loss: 2.3339788913726807, regression loss: 0.6256738901138306, embedding loss: 1.70830500125885\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 126, MAE: 1.3302255868911743, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 127, total loss: 2.3029003143310547, regression loss: 0.6055939197540283, embedding loss: 1.6973063945770264\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 127, MAE: 1.32392156124115, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 128, total loss: 2.34393310546875, regression loss: 0.6343807578086853, embedding loss: 1.70955228805542\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 128, MAE: 1.3290053606033325, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 129, total loss: 2.2980172634124756, regression loss: 0.5986676216125488, embedding loss: 1.6993496417999268\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 129, MAE: 1.3282005786895752, Acc1: 0.616822429906542, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 130, total loss: 2.3194150924682617, regression loss: 0.6126142144203186, embedding loss: 1.706800937652588\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 130, MAE: 1.3291146755218506, Acc1: 0.6121495327102804, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 131, total loss: 2.340344190597534, regression loss: 0.6230881810188293, embedding loss: 1.7172560691833496\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 131, MAE: 1.3280308246612549, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 132, total loss: 2.3221163749694824, regression loss: 0.6195084452629089, embedding loss: 1.7026078701019287\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 132, MAE: 1.3240090608596802, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 133, total loss: 2.2956364154815674, regression loss: 0.5890279412269592, embedding loss: 1.706608533859253\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 133, MAE: 1.3311599493026733, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 134, total loss: 2.2880003452301025, regression loss: 0.5906870365142822, embedding loss: 1.6973133087158203\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 134, MAE: 1.3274630308151245, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 135, total loss: 2.305030584335327, regression loss: 0.5973303914070129, embedding loss: 1.707700252532959\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 135, MAE: 1.3207842111587524, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 136, total loss: 2.304727792739868, regression loss: 0.5972599387168884, embedding loss: 1.707467794418335\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 136, MAE: 1.3235481977462769, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 137, total loss: 2.309314250946045, regression loss: 0.5987715125083923, embedding loss: 1.7105426788330078\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 137, MAE: 1.329628825187683, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 138, total loss: 2.3050968647003174, regression loss: 0.6066349744796753, embedding loss: 1.698461890220642\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 138, MAE: 1.328102946281433, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 139, total loss: 2.275012731552124, regression loss: 0.5747644901275635, embedding loss: 1.7002482414245605\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 139, MAE: 1.324035882949829, Acc1: 0.616822429906542, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 140, total loss: 2.3122432231903076, regression loss: 0.6077870726585388, embedding loss: 1.704456090927124\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 140, MAE: 1.3319628238677979, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 141, total loss: 2.283717393875122, regression loss: 0.564100444316864, embedding loss: 1.7196168899536133\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 141, MAE: 1.3302597999572754, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 142, total loss: 2.3115952014923096, regression loss: 0.5943355560302734, embedding loss: 1.7172596454620361\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 142, MAE: 1.3334925174713135, Acc1: 0.616822429906542, Acc2: 0.6567164179104478\n",
            "start training ---------->>\n",
            "Train Epoch 143, total loss: 2.3064656257629395, regression loss: 0.6008291244506836, embedding loss: 1.7056365013122559\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 143, MAE: 1.3198459148406982, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 144, total loss: 2.294717311859131, regression loss: 0.5841544270515442, embedding loss: 1.7105629444122314\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 144, MAE: 1.3275806903839111, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 145, total loss: 2.29301381111145, regression loss: 0.5808379650115967, embedding loss: 1.7121758460998535\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 145, MAE: 1.3361549377441406, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 146, total loss: 2.3013010025024414, regression loss: 0.6070642471313477, embedding loss: 1.6942367553710938\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 146, MAE: 1.3252317905426025, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 147, total loss: 2.2975757122039795, regression loss: 0.5875056982040405, embedding loss: 1.710070013999939\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 147, MAE: 1.3251060247421265, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 148, total loss: 2.31095290184021, regression loss: 0.6059644222259521, embedding loss: 1.7049884796142578\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 148, MAE: 1.3253109455108643, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 149, total loss: 2.2820045948028564, regression loss: 0.5785337686538696, embedding loss: 1.7034708261489868\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 149, MAE: 1.331542730331421, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 150, total loss: 2.2766172885894775, regression loss: 0.5830200910568237, embedding loss: 1.6935971975326538\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 150, MAE: 1.3260202407836914, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 151, total loss: 2.288999557495117, regression loss: 0.5822361707687378, embedding loss: 1.7067633867263794\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 151, MAE: 1.3249505758285522, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 152, total loss: 2.291938543319702, regression loss: 0.5647557973861694, embedding loss: 1.7271827459335327\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 152, MAE: 1.3176342248916626, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 153, total loss: 2.300069808959961, regression loss: 0.5743752717971802, embedding loss: 1.7256945371627808\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 153, MAE: 1.3177484273910522, Acc1: 0.6121495327102804, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 154, total loss: 2.33044695854187, regression loss: 0.6151590943336487, embedding loss: 1.7152879238128662\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 154, MAE: 1.3277688026428223, Acc1: 0.6121495327102804, Acc2: 0.6517412935323383\n",
            "start training ---------->>\n",
            "Train Epoch 155, total loss: 2.2888786792755127, regression loss: 0.5773254632949829, embedding loss: 1.7115532159805298\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 155, MAE: 1.321679949760437, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 156, total loss: 2.301833391189575, regression loss: 0.5935295224189758, embedding loss: 1.7083039283752441\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 156, MAE: 1.3282153606414795, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 157, total loss: 2.2950491905212402, regression loss: 0.5854161977767944, embedding loss: 1.7096329927444458\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 157, MAE: 1.3275022506713867, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 158, total loss: 2.2532477378845215, regression loss: 0.5473493337631226, embedding loss: 1.705898404121399\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 158, MAE: 1.3199183940887451, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 159, total loss: 2.2919669151306152, regression loss: 0.5774567127227783, embedding loss: 1.714510202407837\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 159, MAE: 1.3208982944488525, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 160, total loss: 2.278862953186035, regression loss: 0.5723500847816467, embedding loss: 1.7065129280090332\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 160, MAE: 1.3278290033340454, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 161, total loss: 2.266648292541504, regression loss: 0.563028872013092, embedding loss: 1.7036194801330566\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 161, MAE: 1.3225274085998535, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 162, total loss: 2.293424367904663, regression loss: 0.5805544853210449, embedding loss: 1.7128698825836182\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 162, MAE: 1.3239223957061768, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 163, total loss: 2.2684173583984375, regression loss: 0.5650550127029419, embedding loss: 1.7033623456954956\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 163, MAE: 1.325523018836975, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 164, total loss: 2.2799055576324463, regression loss: 0.5704382061958313, embedding loss: 1.7094674110412598\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 164, MAE: 1.3242565393447876, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 165, total loss: 2.2810897827148438, regression loss: 0.5741880536079407, embedding loss: 1.7069017887115479\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 165, MAE: 1.3262920379638672, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 166, total loss: 2.261094093322754, regression loss: 0.5623291730880737, embedding loss: 1.6987649202346802\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 166, MAE: 1.3212933540344238, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 167, total loss: 2.255481243133545, regression loss: 0.5480214953422546, embedding loss: 1.7074596881866455\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 167, MAE: 1.324914574623108, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 168, total loss: 2.280609369277954, regression loss: 0.5674167275428772, embedding loss: 1.7131927013397217\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 168, MAE: 1.3227639198303223, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 169, total loss: 2.2659966945648193, regression loss: 0.5507979393005371, embedding loss: 1.7151987552642822\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 169, MAE: 1.3241039514541626, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 170, total loss: 2.263258457183838, regression loss: 0.5503459572792053, embedding loss: 1.7129125595092773\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 170, MAE: 1.3246656656265259, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 171, total loss: 2.28609037399292, regression loss: 0.5733100175857544, embedding loss: 1.7127803564071655\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 171, MAE: 1.3254185914993286, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 172, total loss: 2.2554659843444824, regression loss: 0.5508900880813599, embedding loss: 1.7045758962631226\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 172, MAE: 1.3216845989227295, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 173, total loss: 2.2517709732055664, regression loss: 0.5503283143043518, embedding loss: 1.7014427185058594\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 173, MAE: 1.3222538232803345, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 174, total loss: 2.2695746421813965, regression loss: 0.5617176294326782, embedding loss: 1.7078570127487183\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 174, MAE: 1.3239213228225708, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 175, total loss: 2.292821168899536, regression loss: 0.5867297649383545, embedding loss: 1.7060914039611816\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 175, MAE: 1.3207547664642334, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 176, total loss: 2.245800256729126, regression loss: 0.5426689982414246, embedding loss: 1.7031311988830566\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 176, MAE: 1.325275182723999, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 177, total loss: 2.255615234375, regression loss: 0.558050811290741, embedding loss: 1.6975643634796143\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 177, MAE: 1.3210967779159546, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 178, total loss: 2.2464210987091064, regression loss: 0.5407608151435852, embedding loss: 1.705660343170166\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 178, MAE: 1.3225739002227783, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 179, total loss: 2.2576091289520264, regression loss: 0.5495641827583313, embedding loss: 1.7080450057983398\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 179, MAE: 1.3195422887802124, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 180, total loss: 2.2548489570617676, regression loss: 0.5549614429473877, embedding loss: 1.6998875141143799\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 180, MAE: 1.3191614151000977, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 181, total loss: 2.2738149166107178, regression loss: 0.56427401304245, embedding loss: 1.709540843963623\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 181, MAE: 1.3211919069290161, Acc1: 0.602803738317757, Acc2: 0.6417910447761194\n",
            "start training ---------->>\n",
            "Train Epoch 182, total loss: 2.23710036277771, regression loss: 0.5234519243240356, embedding loss: 1.7136484384536743\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 182, MAE: 1.322840929031372, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 183, total loss: 2.2733633518218994, regression loss: 0.5400680303573608, embedding loss: 1.7332953214645386\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 183, MAE: 1.323555588722229, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 184, total loss: 2.234226942062378, regression loss: 0.5281983017921448, embedding loss: 1.706028699874878\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 184, MAE: 1.3237626552581787, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 185, total loss: 2.2455530166625977, regression loss: 0.5364869832992554, embedding loss: 1.7090660333633423\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 185, MAE: 1.3234378099441528, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 186, total loss: 2.2261486053466797, regression loss: 0.5197769403457642, embedding loss: 1.7063716650009155\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 186, MAE: 1.319496512413025, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 187, total loss: 2.2080061435699463, regression loss: 0.5018730163574219, embedding loss: 1.7061331272125244\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 187, MAE: 1.3222328424453735, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 188, total loss: 2.2522380352020264, regression loss: 0.5317897796630859, embedding loss: 1.7204482555389404\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 188, MAE: 1.3181136846542358, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 189, total loss: 2.256838798522949, regression loss: 0.5493617057800293, embedding loss: 1.70747709274292\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 189, MAE: 1.3221596479415894, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 190, total loss: 2.242948532104492, regression loss: 0.5450341701507568, embedding loss: 1.6979143619537354\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 190, MAE: 1.3273874521255493, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 191, total loss: 2.2379448413848877, regression loss: 0.541179895401001, embedding loss: 1.6967649459838867\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 191, MAE: 1.3142716884613037, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "<------------ Saving Best Model\n",
            "\n",
            "start training ---------->>\n",
            "Train Epoch 192, total loss: 2.2585036754608154, regression loss: 0.5524032711982727, embedding loss: 1.7061004638671875\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 192, MAE: 1.3210694789886475, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 193, total loss: 2.2534589767456055, regression loss: 0.5469473004341125, embedding loss: 1.7065117359161377\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 193, MAE: 1.3184680938720703, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 194, total loss: 2.225579023361206, regression loss: 0.5154656767845154, embedding loss: 1.710113286972046\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 194, MAE: 1.3262054920196533, Acc1: 0.5934579439252337, Acc2: 0.6318407960199005\n",
            "start training ---------->>\n",
            "Train Epoch 195, total loss: 2.224111318588257, regression loss: 0.5286617279052734, embedding loss: 1.6954495906829834\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 195, MAE: 1.3182483911514282, Acc1: 0.6074766355140186, Acc2: 0.6467661691542289\n",
            "start training ---------->>\n",
            "Train Epoch 196, total loss: 2.2354793548583984, regression loss: 0.532099187374115, embedding loss: 1.7033801078796387\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 196, MAE: 1.319619059562683, Acc1: 0.5887850467289719, Acc2: 0.6268656716417911\n",
            "start training ---------->>\n",
            "Train Epoch 197, total loss: 2.2257981300354004, regression loss: 0.5061213970184326, embedding loss: 1.7196767330169678\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 197, MAE: 1.323391079902649, Acc1: 0.5981308411214953, Acc2: 0.6368159203980099\n",
            "start training ---------->>\n",
            "Train Epoch 198, total loss: 2.249953508377075, regression loss: 0.533432126045227, embedding loss: 1.7165213823318481\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 198, MAE: 1.3193358182907104, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "start training ---------->>\n",
            "Train Epoch 199, total loss: 2.2490110397338867, regression loss: 0.5448814034461975, embedding loss: 1.704129695892334\n",
            "Start Evaluating ---------->>\n",
            "Eval Epoch: 199, MAE: 1.3171076774597168, Acc1: 0.5841121495327103, Acc2: 0.6218905472636815\n",
            "Training Time: 1160.815458536148\n",
            "Training Peak Mem: 1244.2890625\n",
            "Training Params: 198809\n",
            "Start Testing ---------->>\n",
            "Test: MAE: 1.3903863430023193, Acc1: 0.4606413994169096, Acc2: 0.4817073170731707\n",
            "Inference Time: 0.658360481262207\n",
            "Inference Params: 198809\n"
          ]
        }
      ]
    }
  ]
}